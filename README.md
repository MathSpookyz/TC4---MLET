# API de PrevisÃ£o de PreÃ§os de AÃ§Ãµes

Sistema completo de previsÃ£o de preÃ§os de aÃ§Ãµes usando modelo LSTM (Long Short-Term Memory) com pipeline ETL automatizado, API REST e monitoramento MLFlow.

## ðŸš€ CaracterÃ­sticas Principais

- âœ… **Multi-ticker**: Suporta qualquer aÃ§Ã£o da bolsa brasileira
- âœ… **Treinamento automÃ¡tico**: Treina modelos sob demanda quando necessÃ¡rio
- âœ… **Armazenamento hÃ­brido**: Local ou S3 via variÃ¡vel de ambiente
- âœ… **MLFlow**: Monitoramento completo de experimentos
- âœ… **Dados personalizados**: Endpoint para treinar/prever com seus prÃ³prios dados
- âœ… **Logs detalhados**: Rastreamento completo de operaÃ§Ãµes
- âœ… **Cache inteligente**: Modelos permanecem em memÃ³ria apÃ³s carregamento

## ðŸ“‹ Requisitos

- Python 3.11+
- Docker (opcional)

## âš¡ InÃ­cio RÃ¡pido

### 1. Instalar DependÃªncias

```bash
pip install -r requirements.txt
```

### 2. Configurar Ambiente (Opcional)

Crie `.env` na raiz do projeto:

```bash
# Armazenamento (padrÃ£o: local)
STORAGE_TYPE=local

# Para usar S3:
# STORAGE_TYPE=s3
# S3_BUCKET=seu-bucket
# AWS_ACCESS_KEY_ID=sua-chave
# AWS_SECRET_ACCESS_KEY=seu-secret

# MLFlow (padrÃ£o: local)
MLFLOW_TRACKING_URI=file:./mlruns
```

### 3. Iniciar API

```bash
python api.py
```

Acesse: http://localhost:8000/docs

## ðŸ“Š Como Usar

### Treinar um Modelo

#### Via Linha de Comando

```bash
python model/model_training.py
```

O sistema solicitarÃ¡ o ticker (ex: PETR4.SA, VALE3.SA, ITUB4.SA)

#### Via API

```bash
# Treinar modelo via API
curl -X POST http://localhost:8000/train \
  -H "Content-Type: application/json" \
  -d '{"ticker": "VALE3.SA", "start_date": "2020-01-01"}'
```

### Fazer PrevisÃµes

#### PrevisÃ£o Simples (com treinamento automÃ¡tico)

```bash
# O sistema treina automaticamente se o modelo nÃ£o existir
curl "http://localhost:8000/predict/PETR4.SA?days=7"
```

#### Via API - GET

```bash
# PrevisÃ£o de 1 dia para VALE3.SA
curl http://localhost:8000/predict/VALE3.SA

# PrevisÃ£o de 7 dias
curl "http://localhost:8000/predict/VALE3.SA?days=7"

# Com perÃ­odo especÃ­fico
curl "http://localhost:8000/predict/ITUB4.SA?days=5&start_date=2023-01-01&end_date=2024-12-31"
```

#### Via API - POST

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "ticker": "PETR4.SA",
    "days": 30,
    "start_date": "2023-01-01",
    "end_date": "2024-12-31"
  }'
```

### Estrutura de Resposta

#### Treinamento

```json
{
  "ticker": "VALE3.SA",
  "status": "success",
  "message": "Modelo treinado com sucesso para VALE3.SA",
  "rmse": 2.45,
  "next_prediction": 65.32,
  "trained_at": "2026-01-07T10:30:00.000000"
}
```

#### PrevisÃ£o

```json
{
  "ticker": "VALE3.SA",
  "predictions": [65.32, 65.87, 66.15],
  "days": 3,
  "last_known_price": 64.80,
  "currency": "BRL"
}
```

### Usar Dados Personalizados

O endpoint `/predict-custom` permite treinar um modelo temporÃ¡rio com seus prÃ³prios dados histÃ³ricos. Ideal para:

- Testar estratÃ©gias com dados histÃ³ricos especÃ­ficos
- Fazer previsÃµes com dados sintÃ©ticos ou simulados
- Validar o modelo sem interferir com modelos salvos
- Treinar e prever sem dependÃªncia de tickers da bolsa

#### CaracterÃ­sticas do Endpoint Custom

âœ… **Isolado**: NÃ£o salva o modelo no disco  
âœ… **TemporÃ¡rio**: Modelo existe apenas durante a requisiÃ§Ã£o  
âœ… **FlexÃ­vel**: Aceita qualquer conjunto de dados histÃ³ricos  
âœ… **Completo**: Retorna mÃ©tricas de treinamento (RMSE)

#### Requisitos de Dados

- **MÃ­nimo**: 30 pontos histÃ³ricos
- **Recomendado**: 60+ pontos para melhor acurÃ¡cia
- **Formato**: JSON com date, close e volume

#### Exemplo de Uso

```bash
curl -X POST http://localhost:8000/predict-custom \
  -H "Content-Type: application/json" \
  -d '{
    "ticker_name": "TESTE",
    "days": 5,
    "historical_data": [
      {"date": "2024-01-01", "close": 100.5, "volume": 1000000},
      {"date": "2024-01-02", "close": 101.2, "volume": 1100000},
      ... (mÃ­nimo 30 pontos)
    ]
  }'
```

#### Usando Arquivo JSON

```bash
# Usar dados do arquivo de exemplo incluÃ­do no projeto
curl -X POST http://localhost:8000/predict-custom \
  -H "Content-Type: application/json" \
  -d @example_custom_data.json
```

#### Teste RÃ¡pido

```bash
curl -X POST http://localhost:8000/predict-custom \
  -H "Content-Type: application/json" \
  -d '{
    "ticker_name": "TESTE_RAPIDO",
    "days": 3,
    "historical_data": [
      {"date": "2024-01-01", "close": 100.00, "volume": 1000000},
      {"date": "2024-01-02", "close": 101.50, "volume": 1050000},
      {"date": "2024-01-03", "close": 102.30, "volume": 1100000},
      {"date": "2024-01-04", "close": 101.80, "volume": 1080000},
      {"date": "2024-01-05", "close": 103.20, "volume": 1120000},
      {"date": "2024-01-08", "close": 104.50, "volume": 1150000},
      {"date": "2024-01-09", "close": 104.00, "volume": 1130000},
      {"date": "2024-01-10", "close": 105.30, "volume": 1180000},
      {"date": "2024-01-11", "close": 106.20, "volume": 1200000},
      {"date": "2024-01-12", "close": 105.80, "volume": 1190000},
      {"date": "2024-01-15", "close": 107.50, "volume": 1220000},
      {"date": "2024-01-16", "close": 108.10, "volume": 1250000},
      {"date": "2024-01-17", "close": 108.90, "volume": 1260000},
      {"date": "2024-01-18", "close": 108.30, "volume": 1240000},
      {"date": "2024-01-19", "close": 109.80, "volume": 1280000},
      {"date": "2024-01-22", "close": 110.50, "volume": 1300000},
      {"date": "2024-01-23", "close": 110.20, "volume": 1290000},
      {"date": "2024-01-24", "close": 111.60, "volume": 1320000},
      {"date": "2024-01-25", "close": 112.30, "volume": 1350000},
      {"date": "2024-01-26", "close": 111.90, "volume": 1340000},
      {"date": "2024-01-29", "close": 113.20, "volume": 1370000},
      {"date": "2024-01-30", "close": 114.00, "volume": 1400000},
      {"date": "2024-01-31", "close": 113.60, "volume": 1390000},
      {"date": "2024-02-01", "close": 114.80, "volume": 1420000},
      {"date": "2024-02-02", "close": 115.50, "volume": 1450000},
      {"date": "2024-02-05", "close": 115.20, "volume": 1440000},
      {"date": "2024-02-06", "close": 116.30, "volume": 1470000},
      {"date": "2024-02-07", "close": 117.00, "volume": 1490000},
      {"date": "2024-02-08", "close": 116.70, "volume": 1480000},
      {"date": "2024-02-09", "close": 117.90, "volume": 1510000}
    ]
  }'
```

**Resposta esperada:**
```json
{
  "ticker_name": "TESTE_RAPIDO",
  "predictions": [118.45, 119.12, 119.78],
  "days": 3,
  "last_known_price": 117.90,
  "rmse": 0.87,
  "training_samples": 0,
  "message": "Modelo treinado e previsÃ£o realizada com sucesso usando 30 pontos histÃ³ricos"
}
```

#### Estrutura dos Dados

Cada ponto histÃ³rico deve conter:

```json
{
  "date": "YYYY-MM-DD",
  "close": float,
  "volume": int
}
```

#### ParÃ¢metros

| Campo | Tipo | ObrigatÃ³rio | DescriÃ§Ã£o |
|-------|------|-------------|-----------|
| `ticker_name` | string | NÃ£o | Nome para identificaÃ§Ã£o (padrÃ£o: "CUSTOM") |
| `days` | integer | NÃ£o | Dias para prever (padrÃ£o: 1) |
| `historical_data` | array | Sim | Lista de pontos histÃ³ricos (mÃ­nimo 30) |

#### Resposta do Endpoint Custom

```json
{
  "ticker_name": "MINHA_ACAO",
  "predictions": [102.45, 103.12, 103.78, 104.21, 104.67],
  "days": 5,
  "last_known_price": 101.80,
  "rmse": 1.23,
  "training_samples": 120,
  "message": "Modelo treinado e previsÃ£o realizada com sucesso usando 150 pontos histÃ³ricos"
}
```

#### Campos da Resposta

| Campo | Tipo | DescriÃ§Ã£o |
|-------|------|-----------|
| `ticker_name` | string | Nome fornecido na requisiÃ§Ã£o |
| `predictions` | array | Lista de previsÃµes (um valor por dia) |
| `days` | integer | NÃºmero de dias previstos |
| `last_known_price` | float | Ãšltimo preÃ§o real conhecido |
| `rmse` | float | Root Mean Square Error do modelo |
| `training_samples` | integer | NÃºmero de sequÃªncias usadas no treino |
| `message` | string | Mensagem descritiva |

#### Erros Comuns

**400 - Dados Insuficientes**
```json
{"detail": "MÃ­nimo de 30 pontos histÃ³ricos necessÃ¡rios. Fornecidos: 20"}
```
SoluÃ§Ã£o: Fornecer pelo menos 30 pontos de dados histÃ³ricos.

**400 - Formato InvÃ¡lido**
```json
{"detail": "Campo 'close' invÃ¡lido no ponto 5"}
```
SoluÃ§Ã£o: Verificar se todos os pontos tÃªm date, close e volume vÃ¡lidos.

#### Casos de Uso do Endpoint Custom

1. **ValidaÃ§Ã£o de EstratÃ©gias**: Teste sua estratÃ©gia de trading com dados histÃ³ricos especÃ­ficos
2. **Testes com Dados SintÃ©ticos**: Valide o modelo com dados gerados
3. **AnÃ¡lise What-If**: "E se os preÃ§os tivessem evoluÃ­do diferente?"
4. **Backtesting**: Teste o modelo com perÃ­odos histÃ³ricos especÃ­ficos

#### Performance do Endpoint Custom

| MÃ©trica | Valor TÃ­pico |
|---------|--------------|
| Tempo (50 pontos) | 10-20 segundos |
| Tempo (100 pontos) | 20-40 segundos |
| Tempo (200 pontos) | 40-80 segundos |
| MemÃ³ria utilizada | ~500 MB |

## ðŸŽ¯ Endpoints da API

| MÃ©todo | Endpoint | DescriÃ§Ã£o |
|--------|----------|-----------|
| GET | `/` | InformaÃ§Ãµes da API |
| GET | `/health` | Health check |
| GET | `/predict/{ticker}` | PrevisÃ£o para ticker (params: days, start_date, end_date) |
| POST | `/predict` | PrevisÃ£o com JSON completo |
| POST | `/train` | Treinar modelo para ticker |
| POST | `/predict-custom` | Treinar/prever com dados personalizados (isolado) |

### ComparaÃ§Ã£o de Endpoints

| CaracterÃ­stica | `/predict/{ticker}` | `/train` | `/predict-custom` |
|----------------|---------------------|----------|-------------------|
| Usa dados do Yahoo Finance | âœ… | âœ… | âŒ |
| Salva modelo | âŒ | âœ… | âŒ |
| Dados personalizados | âŒ | âŒ | âœ… |
| Cache de modelos | âœ… | âœ… | âŒ |
| Retorna RMSE | âŒ | âœ… | âœ… |
| Isolado | âŒ | âŒ | âœ… |

## ðŸ—ï¸ Arquitetura do Sistema

### Componentes Principais

**Pipeline ETL**
- `yahoo_extractor.py` - ExtraÃ§Ã£o de dados do Yahoo Finance
- `price_transformer.py` - Feature engineering (mÃ©dias mÃ³veis, volatilidade, retornos)
- `parquet_loader.py` - Armazenamento hÃ­brido (local/S3)
- `scrapper_pipeline.py` - OrquestraÃ§Ã£o do pipeline

**Machine Learning**
- `model_training.py` - Treinamento LSTM com MLFlow
- `model_executor.py` - Carregamento e inferÃªncia de modelos

**API REST**
- `api.py` - FastAPI com endpoints de previsÃ£o e treinamento

### Fluxo de Dados

```
Cliente â†’ API â†’ Verifica Cache Local â†’ Se nÃ£o existe â†’ Yahoo Finance
                     â†“                                        â†“
                 Model LSTM â† Dados Processados â† Feature Engineering
                     â†“
                 PrevisÃ£o â†’ Resposta JSON â†’ Cliente
```

### Modelo LSTM

- **Arquitetura**: 2 camadas LSTM, 64 neurÃ´nios por camada
- **Features**: PreÃ§o de fechamento + Volume
- **Janela temporal**: 30 dias
- **NormalizaÃ§Ã£o**: MinMaxScaler
- **Armazenamento**: `export/lstm_model_{TICKER}.pth`

## ðŸ“¦ Estrutura do Projeto

```
â”œâ”€â”€ api.py                          # API REST FastAPI
â”œâ”€â”€ model_executor.py               # InferÃªncia de modelos
â”œâ”€â”€ requirements.txt                # DependÃªncias Python
â”œâ”€â”€ docker-compose.yml              # OrquestraÃ§Ã£o Docker
â”œâ”€â”€ model/
â”‚   â””â”€â”€ model_training.py          # Treinamento LSTM + MLFlow
â”œâ”€â”€ scrapper/
â”‚   â”œâ”€â”€ scrapper_pipeline.py       # OrquestraÃ§Ã£o ETL
â”‚   â”œâ”€â”€ scr/
â”‚   â”‚   â”œâ”€â”€ extract/
â”‚   â”‚   â”‚   â””â”€â”€ yahoo_extractor.py # ExtraÃ§Ã£o Yahoo Finance
â”‚   â”‚   â”œâ”€â”€ transform/
â”‚   â”‚   â”‚   â””â”€â”€ price_transformer.py # Feature engineering
â”‚   â”‚   â””â”€â”€ load/
â”‚   â”‚       â””â”€â”€ parquet_loader.py  # Armazenamento local/S3
â”‚   â””â”€â”€ data/                      # Dados locais (raw + processed)
â””â”€â”€ export/                        # Modelos treinados e scalers
```

## ðŸ³ Docker

### Executar com Docker Compose (Recomendado)

```bash
# Iniciar
docker-compose up -d

# Ver logs
docker-compose logs -f

# Parar
docker-compose down
```

### Docker Standalone

```bash
# Build
docker build -t stock-api .

# Run
docker run -d -p 8000:8000 stock-api
```

## ðŸ“ˆ MLFlow - Monitoramento de Experimentos

O sistema usa MLFlow para rastrear todos os treinamentos.

### Visualizar Experimentos

```bash
# Iniciar MLFlow UI
mlflow ui

# Acessar em: http://localhost:5000
```

**MÃ©tricas rastreadas:**
- **ParÃ¢metros**: ticker, datas, Ã©pocas, learning rate, batch size
- **MÃ©tricas**: RMSE, loss por Ã©poca, Ãºltima previsÃ£o
- **Artefatos**: Modelos salvos (`.pth`), scalers (`.save`)
- **Tags**: versÃ£o, timestamp, duraÃ§Ã£o do treinamento

### Comparar Modelos

No MLFlow UI vocÃª pode:
- Comparar RMSE entre diferentes tickers
- Ver evoluÃ§Ã£o do loss durante treinamento
- Analisar distribuiÃ§Ã£o de previsÃµes
- Baixar modelos de versÃµes anteriores
- Filtrar experimentos por parÃ¢metros
- Exportar resultados para anÃ¡lise

## ðŸ’¡ Exemplos PrÃ¡ticos

### Exemplo 1: Treinar MÃºltiplos Tickers

```bash
# Treinar PETR4
curl -X POST http://localhost:8000/train \
  -H "Content-Type: application/json" \
  -d '{"ticker": "PETR4.SA"}'

# Treinar VALE3
curl -X POST http://localhost:8000/train \
  -H "Content-Type: application/json" \
  -d '{"ticker": "VALE3.SA"}'

# Treinar ITUB4
curl -X POST http://localhost:8000/train \
  -H "Content-Type: application/json" \
  -d '{"ticker": "ITUB4.SA"}'
```

### Exemplo 2: PrevisÃµes para MÃºltiplos Tickers

```bash
# PETR4 - 7 dias
curl "http://localhost:8000/predict/PETR4.SA?days=7"

# VALE3 - 30 dias
curl "http://localhost:8000/predict/VALE3.SA?days=30"

# ITUB4 - 14 dias
curl "http://localhost:8000/predict/ITUB4.SA?days=14"
```

### Exemplo 3: Dados Personalizados

```bash
# Criar arquivo com dados histÃ³ricos
cat > custom_data.json << 'EOF'
{
  "ticker_name": "TESTE_ACAO",
  "days": 7,
  "historical_data": [
    {"date": "2024-01-01", "close": 50.00, "volume": 1000000},
    {"date": "2024-01-02", "close": 50.50, "volume": 1050000},
    {"date": "2024-01-03", "close": 51.20, "volume": 1100000},
    ... (mÃ­nimo 30 pontos)
  ]
}
EOF

# Fazer previsÃ£o com dados personalizados
curl -X POST http://localhost:8000/predict-custom \
  -H "Content-Type: application/json" \
  -d @custom_data.json
```

**Vantagens do endpoint custom:**
- NÃ£o precisa ter o ticker na bolsa
- Ãštil para testes com dados sintÃ©ticos
- NÃ£o interfere com modelos salvos
- Permite validaÃ§Ã£o de estratÃ©gias com dados histÃ³ricos especÃ­ficos

Veja tambÃ©m:
- [example_custom_prediction.py](example_custom_prediction.py) - Script completo de exemplo
- [example_custom_data.json](example_custom_data.json) - Dados de exemplo prontos (45 pontos histÃ³ricos)

**Scripts incluÃ­dos:**
```bash
# Script completo com geraÃ§Ã£o automÃ¡tica de dados
python example_custom_prediction.py

# Usar dados do arquivo JSON de exemplo
curl -X POST http://localhost:8000/predict-custom \
  -H "Content-Type: application/json" \
  -d @example_custom_data.json
```

### Exemplo 4: Treinamento AutomÃ¡tico

```bash
# Execute o script de demonstraÃ§Ã£o
python example_auto_train.py
```

### Exemplo 5: Script Python para MÃºltiplos Tickers

```python
import requests

tickers = ['PETR4.SA', 'VALE3.SA', 'ITUB4.SA']
for ticker in tickers:
    r = requests.post('http://localhost:8000/train', 
                      json={'ticker': ticker})
    print(f'{ticker}: {r.json()}')
```

## ðŸ”§ Troubleshooting

### Erro: "Modelo nÃ£o encontrado"
- **SoluÃ§Ã£o AutomÃ¡tica**: O sistema agora treina automaticamente modelos inexistentes
- **Manual**: VocÃª ainda pode treinar explicitamente com `POST /train` se preferir

### Erro: "Dados insuficientes"
- **SoluÃ§Ã£o**: Ajustar `start_date` para obter mais histÃ³rico (mÃ­nimo 30 registros)

### Erro: "Ticker nÃ£o encontrado"
- **SoluÃ§Ã£o**: Verificar se o ticker estÃ¡ correto (ex: PETR4.SA, nÃ£o PETR4)

### Erro: "MÃ­nimo de 30 pontos histÃ³ricos necessÃ¡rios"
- **SoluÃ§Ã£o**: Para `/predict-custom`, fornecer pelo menos 30 pontos de dados histÃ³ricos
- **RecomendaÃ§Ã£o**: Use 60+ pontos para melhor acurÃ¡cia do modelo

### Treinamento Muito Lento (Endpoint Custom)
- **SoluÃ§Ã£o 1**: Reduza o nÃºmero de pontos histÃ³ricos
- **SoluÃ§Ã£o 2**: Verifique recursos do servidor (CPU/RAM)
- **SoluÃ§Ã£o 3**: Aumente o timeout do cliente (padrÃ£o: 300s)

### RMSE Muito Alto
- **SoluÃ§Ã£o 1**: Verifique a qualidade dos dados
- **SoluÃ§Ã£o 2**: Aumente o nÃºmero de pontos histÃ³ricos
- **SoluÃ§Ã£o 3**: Verifique se hÃ¡ valores ausentes ou inconsistentes

### Erro: ModuleNotFoundError
- **SoluÃ§Ã£o**: Verificar se todas as dependÃªncias foram instaladas com `pip install -r requirements.txt`

### API nÃ£o responde
- **SoluÃ§Ã£o**: Verificar se a porta 8000 estÃ¡ disponÃ­vel e o serviÃ§o estÃ¡ rodando

### Ver Logs Detalhados

O sistema possui logs detalhados em todos os processos:

```python
import logging

# Configurar nÃ­vel de log
logging.basicConfig(
    level=logging.DEBUG,  # Para logs muito detalhados
    format="%(asctime)s | %(name)s | %(levelname)s | %(message)s"
)

# Rodar a aplicaÃ§Ã£o
# VocÃª verÃ¡ logs de:
# - Carregamento de modelos
# - VerificaÃ§Ã£o de arquivos
# - Treinamento automÃ¡tico
# - PreparaÃ§Ã£o de dados
# - PrevisÃµes
```

## ðŸ“Š Performance

| MÃ©trica | Valor |
|---------|-------|
| Tempo com cache | 2-5 segundos |
| Tempo sem cache (1Âª vez) | 10-20 segundos |
| Tamanho Docker image | ~2-3GB |
| MemÃ³ria requerida | ~2GB RAM |

## ðŸŽ“ Tickers Suportados

Qualquer ticker do Yahoo Finance (formato: CODIGO.SA para Brasil):

- **Bancos**: ITUB4.SA, BBDC4.SA, SANB11.SA
- **Energia**: PETR4.SA, ELET3.SA
- **MineraÃ§Ã£o**: VALE3.SA
- **Varejo**: MGLU3.SA, LREN3.SA
- **E muito mais...**

## ðŸ“š DocumentaÃ§Ã£o Adicional

- **Swagger UI** - http://localhost:8000/docs (documentaÃ§Ã£o interativa completa)
- **ReDoc** - http://localhost:8000/redoc (documentaÃ§Ã£o alternativa)
- **MLFlow UI** - http://localhost:5000 (apÃ³s executar `mlflow ui`)

### DocumentaÃ§Ã£o da API

A API possui documentaÃ§Ã£o interativa automÃ¡tica gerada pelo FastAPI:

1. **Swagger UI**: Interface interativa onde vocÃª pode testar todos os endpoints
   - Acesse: http://localhost:8000/docs
   - Recursos: Teste de endpoints, visualizaÃ§Ã£o de schemas, exemplos

2. **ReDoc**: DocumentaÃ§Ã£o alternativa em formato de pÃ¡gina Ãºnica
   - Acesse: http://localhost:8000/redoc
   - Recursos: VisualizaÃ§Ã£o limpa, navegaÃ§Ã£o fÃ¡cil, download de spec OpenAPI

## âš™ï¸ Arquivos de Exemplo

- **example_auto_train.py** - DemonstraÃ§Ã£o de treinamento automÃ¡tico
- **example_custom_prediction.py** - Exemplo completo de uso do endpoint custom
- **example_custom_data.json** - Dados de exemplo prontos para uso
- **test_system.py** - Script de teste completo do sistema

## ðŸ”— Links Ãšteis

- [FastAPI](https://fastapi.tiangolo.com/)
- [PyTorch](https://pytorch.org/)
- [MLFlow](https://mlflow.org/)
- [Yahoo Finance](https://finance.yahoo.com/)

## ðŸ“ Notas Importantes

1. âœ… **Treinamento automÃ¡tico** - O sistema detecta automaticamente quando um modelo nÃ£o existe e treina sob demanda
2. ðŸ“¦ **Modelos independentes** - Cada ticker tem seu prÃ³prio modelo (`export/lstm_model_{TICKER}.pth`)
3. ðŸ’¾ **Cache local** - Dados sÃ£o salvos localmente para evitar downloads repetidos do Yahoo Finance
4. ðŸ” **Logs detalhados** - Todo o processo Ã© logado para fÃ¡cil debugging
5. âš™ï¸ **ConfiguraÃ§Ã£o flexÃ­vel** - Use variÃ¡veis de ambiente para alternar entre local/S3
6. ðŸš€ **Pronto para produÃ§Ã£o** - Suporte completo para Docker e MLFlow
7. â±ï¸ **Tempo de treinamento** - O treinamento leva geralmente 2-5 minutos por ticker

## ðŸ”„ Fluxo de Trabalho Recomendado

### Para um Novo Ticker

1. **Simplesmente faÃ§a a previsÃ£o**:
   ```bash
   curl "http://localhost:8000/predict/NOVO_TICKER.SA?days=7"
   ```
   O sistema irÃ¡ automaticamente:
   - Buscar dados do Yahoo Finance
   - Treinar o modelo
   - Fazer a previsÃ£o

2. **Ou treine explicitamente** (opcional):
   ```bash
   curl -X POST http://localhost:8000/train \
     -H "Content-Type: application/json" \
     -d '{"ticker": "NOVO_TICKER.SA"}'
   ```

### Para Retreinar um Ticker Existente

Simplesmente execute o treinamento novamente. O novo modelo substituirÃ¡ o anterior:

```bash
curl -X POST http://localhost:8000/train \
  -H "Content-Type: application/json" \
  -d '{"ticker": "PETR4.SA", "start_date": "2020-01-01"}'
```

---

**Desenvolvido para FIAP - Sistema de PrevisÃ£o de AÃ§Ãµes com Machine Learning**